Output folder: output/figurines_debug_2 [26/04 14:50:41]







Reading camera 303/303 [26/04 14:50:58]
Loading Training Cameras [26/04 14:50:58]
Loading Test Cameras [26/04 14:51:15]
Number of points at initialisation :  50613 [26/04 14:51:15]
[38mic| gaussians.get_xyz.shape: torch.Size([3598368, 3])
Training progress:   0%|                                                                                                | 0/60000 [00:00<?, ?it/s]









Training progress:   0%|                                                                    | 100/60000 [00:44<4:12:10,  3.96it/s, Loss=0.0707310][38mic| import_score.shape: torch.Size([3598368, 1])
Training progress:   0%|                                                                    | 110/60000 [00:45<3:17:54,  5.04it/s, Loss=0.5917424]
Before prune iteration, number of gaussians: 3598368 [26/04 14:52:10]
































Training progress:   2%|█                                                                  | 1000/60000 [01:48<1:33:09, 10.55it/s, Loss=0.2254249]
[ITER 1000] Evaluating train: L1 0.08339851722121239 PSNR 18.86450538635254 [26/04 14:53:20]

















































































































































































































































































































































Training progress:   8%|█████▏                                                             | 4600/60000 [15:15<4:04:55,  3.77it/s, Loss=0.1474605]Traceback (most recent call last):
  File "train_prune.py", line 325, in <module>
    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint,args.start_pointcloud, args.loaded_iteration,args.debug_from, args.use_wandb)
  File "train_prune.py", line 135, in training
    loss.backward()
  File "/scratch/jiasi_root/jiasi98/shared_env/gaussian_grouping/lib/python3.8/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/scratch/jiasi_root/jiasi98/shared_env/gaussian_grouping/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA out of memory. Tried to allocate 4.19 GiB (GPU 0; 44.35 GiB total capacity; 30.25 GiB already allocated; 4.01 GiB free; 38.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF